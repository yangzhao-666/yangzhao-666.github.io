<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Kenneth Li</title>
  
  <meta name="author" content="Kenneth Li">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/png" href="images/seal_icon.png">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Kenneth Li</name>
              </p>
              <p>
                I am a second-year PhD student at Harvard, advised by <a href="https://vcg.seas.harvard.edu/people/hanspeter-pfister">Hanspeter Pfister</a>. Previously, I studied Computer Science at (University of) Chinese Academy of Sciences, and interned at <a href="https://www.microsoft.com/en-us/research/lab/microsoft-research-asia/">MSR Asia</a> and <a href="https://ai.facebook.com/">Meta AI</a>. 
              </p>

              <p>
                My research interests span Machine Learning, Visualization, Computer Vision and Natural Language Processing. I aim at understanding the rich inner world of deep neural networks with mechanistic approaches. I also enjoy learning about how other complex systems work, e.g., market, human mind.
              </p>
              <p style="text-align:center">

              </p>
              <p style="text-align:center">
                Contact: ke_li [at] g.harvard.edu <br>
<!--                Address: 150 Western Ave, Allston, MA 02134 <br>-->
<!--                <a href="mailto:ke_li@g.harvard.edu">Email</a> &nbsp|&nbsp-->
<!--                <a href="data/JonBarron-CV.pdf">CV</a> &nbsp|&nbsp-->
<!--                <a href="data/JonBarron-bio.txt">Bio</a> &nbsp|nbsp-->
                <a href="https://scholar.google.com/citations?user=v0GItgwAAAAJ&hl">Google Scholar</a> &nbsp|&nbsp
                <a href="https://www.linkedin.com/in/kenneth-li-103072201/">LinkedIn</a> &nbsp|&nbsp
                <a href="https://twitter.com/ke_li_2021">Twitter</a> &nbsp|&nbsp
                <a href="https://github.com/likenneth">Github</a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/KennethLi.jpg"><img style="width:100%;max-width:100%" alt="profile photo" src="images/KennethLi_circle.jpg" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Research</heading>
<!--              <p>-->
<!--                Representative papers are <span class="highlight">highlighted</span>.-->
<!--              </p>-->
            </td>
          </tr>
        </tbody></table>

        <!-- Add border="1" here to debug-->
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

        <!-- This is an example of a highlighted project with animation effects-->
<!--          <tr onmouseout="mipnerf_stop()" onmouseover="mipnerf_start()"  bgcolor="#ffffd0">-->
<!--            <td style="padding:20px;width:25%;vertical-align:middle">-->
<!--              <div class="one">-->
<!--                <div class="two" id='mipnerf_image'><video  width=100% height=100% muted autoplay loop>-->
<!--                <source src="images/mipnerf_ipe_yellow.mp4" type="video/mp4">-->
<!--                Your browser does not support the video tag.-->
<!--                </video></div>-->
<!--                <img src='images/mipnerf_ipe_yellow.png' width="160">-->
<!--              </div>-->
<!--              <script type="text/javascript">-->
<!--                function mipnerf_start() {-->
<!--                  document.getElementById('mipnerf_image').style.opacity = "1";-->
<!--                }-->

<!--                function mipnerf_stop() {-->
<!--                  document.getElementById('mipnerf_image').style.opacity = "0";-->
<!--                }-->
<!--                mipnerf_stop()-->
<!--              </script>-->
<!--            </td>-->
<!--            <td style="padding:20px;width:75%;vertical-align:middle">-->
<!--              <a href="http://jonbarron.info/mipnerf">-->
<!--                <papertitle>Mip-NeRF: A Multiscale Representation for Anti-Aliasing Neural Radiance Fields</papertitle>-->
<!--              </a>-->
<!--              <br>-->
<!--              <strong>Jonathan T. Barron</strong>,-->
<!--              <a href="https://bmild.github.io/">Ben Mildenhall</a>,-->
<!--              <a href="http://matthewtancik.com/">Matthew Tancik</a>, <br>-->
<!--              <a href="https://phogzone.com/">Peter Hedman</a>,-->
<!--              <a href="http://www.ricardomartinbrualla.com/">Ricardo Martin-Brualla</a>,-->
<!--              <a href="https://pratulsrinivasan.github.io/">Pratul Srinivasan</a>-->
<!--              <br>-->
<!--							<em>ICCV</em>, 2021 &nbsp <font color="red"><strong>(Oral Presentation)</strong></font>-->
<!--              <br>-->
<!--              <a href="http://jonbarron.info/mipnerf">project page</a>-->
<!--              /-->
<!--              <a href="https://arxiv.org/abs/2103.13415">arXiv</a>-->
<!--              /-->
<!--              <a href="https://youtu.be/EpH175PY1A0">video</a>-->
<!--							/-->
<!--              <a href="https://github.com/google/mipnerf">code</a>-->
<!--              <p></p>-->
<!--              <p>NeRF is aliased, but we can anti-alias it by casting cones and prefiltering the positional encoding function.</p>-->
<!--            </td>-->
<!--          </tr> -->

        <!-- This is an example of a plain project with animation effects-->
<!--          <tr onmouseout="nerfbake_stop()" onmouseover="nerfbake_start()">-->
<!--            <td style="padding:20px;width:25%;vertical-align:middle">-->
<!--              <div class="one">-->
<!--                <div class="two" id='nerfbake_image'><video  width=100% height=100% muted autoplay loop>-->
<!--                <source src="images/nerfbake_15.mp4" type="video/mp4">-->
<!--                Your browser does not support the video tag.-->
<!--                </video></div>-->
<!--                <img src='images/nerfbake_160.png' width="160">-->
<!--              </div>-->
<!--              <script type="text/javascript">-->
<!--                function nerfbake_start() {-->
<!--                  document.getElementById('nerfbake_image').style.opacity = "1";-->
<!--                }-->

<!--                function nerfbake_stop() {-->
<!--                  document.getElementById('nerfbake_image').style.opacity = "0";-->
<!--                }-->
<!--                nerfbake_stop()-->
<!--              </script>-->
<!--            </td>-->
<!--            <td style="padding:20px;width:75%;vertical-align:middle">-->
<!--              <a href="http://nerf.live">-->
<!--              <papertitle>Baking Neural Radiance Fields for Real-Time View Synthesis</papertitle>-->
<!--              </a>-->
<!--              <br>-->
<!--              <a href="https://phogzone.com/">Peter Hedman</a>,-->
<!--              <a href="https://pratulsrinivasan.github.io/">Pratul Srinivasan</a>,-->
<!--              <a href="https://bmild.github.io/">Ben Mildenhall</a>,-->
<!--              <strong>Jonathan T. Barron</strong>,-->
<!--              <a href="https://www.pauldebevec.com/">Paul Debevec</a>-->
<!--              <br>-->
<!--							<em>ICCV</em>, 2021 &nbsp <font color="red"><strong>(Oral Presentation)</strong></font>-->
<!--              <br>-->
<!--              <a href="http://nerf.live">project page</a>-->
<!--              /-->
<!--              <a href="https://arxiv.org/abs/2103.14645">arXiv</a>-->
<!--              /-->
<!--              <a href="https://www.youtube.com/watch?v=5jKry8n5YO8">video</a>-->
<!--              /-->
<!--              <a href="https://nerf.live/#demos">demo</a>-->
<!--              <p></p>-->
<!--              <p>Baking a trained NeRF into a sparse voxel grid of colors and features lets you render it in real-time in your browser.</p>-->
<!--            </td>-->

          <tr>
            <td style="padding:8px;width:1%;vertical-align:middle">
              <img src="images/white.jpg" alt="clean-usnob" width="1" height="1">
            </td>
            <td width="75%" valign="middle">
              <a href="https://arxiv.org/pdf/2210.13382.pdf">
                <papertitle>Emergent World Representations: Exploring a Sequence Model Trained on a Synthetic Task</papertitle>
              </a>
              <br>
              <strong>Kenneth Li</strong>, Aspen K. Hopkins, David Bau, Fernanda Vi√©gas, Hanspeter Pfister, Martin Wattenberg
              <br>
              <em>ICLR</em>, 2023 <font color="red"><strong>(Oral Presentation)</strong></font>
              <br>
              <a href="https://arxiv.org/abs/2210.13382">Arxiv</a> | <a href="https://github.com/likenneth/othello_world">Code</a> | <a href="othello/togglable.html">Demo</a> | <a href="https://thegradient.pub/othello/">The Gradient</a>
              <br>From a GPT trained on Othello game transcripts, we discover an interpretable and controllable world representation of the game board. 
              <p></p>
            </td>
          </tr>

          <tr>
            <td style="padding:8px;width:1%;vertical-align:middle">
              <img src="images/white.jpg" alt="clean-usnob" width="1" height="1">
            </td>
            <td width="75%" valign="middle">
              <a href="https://arxiv.org/pdf/2111.11433.pdf">
                <papertitle>Towards Tokenized Human Dynamics Representation</papertitle>
              </a>
              <br>
              <strong>Kenneth Li</strong>, Xiao Sun, Zhirong Wu, Fangyun Wei, Stephen Lin
              <br>
              preprint
              <br>
              <a href="https://arxiv.org/abs/2111.11433">Arxiv</a> | <a href="https://github.com/likenneth/acton">Code</a> | <a href="https://drive.google.com/file/d/1JJpc-WzrggQU8xT8TZLdW2ytW5Xk090d/view">Demo</a>
              <br>By self-supervised acton discovery, we convert human dynamics understanding into a language problem.
              <p></p>
            </td>
          </tr>

          <tr>
            <td style="padding:8px;width:1%;vertical-align:middle">
              <img src="images/white.jpg" alt="clean-usnob" width="1" height="1">
            </td>
            <td width="75%" valign="middle">
              <a href="https://arxiv.org/pdf/2104.06976.pdf">
                <papertitle>Pose Recognition with Cascade Transformers</papertitle>
              </a>
              <br>
              <strong>Ke Li</strong>*, Shijie Wang*, Xiang Zhang*, Yifan Xu, Weijian Xu, Zhuowen Tu
              <br>
              <em>CVPR</em>, 2021
              <br>
              <a href="https://arxiv.org/abs/2104.06976">Arxiv</a> | <a href="https://github.com/mlpc-ucsd/PRTR">Code</a> | <a href="https://0633e92166c0a27ea1aa-ab47878a9e45eb9e2f15be38a59f867e.ssl.cf1.rackcdn.com/TFCCYRWN-1700030-1332322-Upload-1622494976.mp4">Video</a>
              <br>By using Transformer architecture, we can clean up heuristic designs that has long bedeviled pose estimation models in an end-to-end fashion.
              <p></p>
            </td>
          </tr>

          <!-- <tr>
            <td style="padding:8px;width:1%;vertical-align:middle">
              <img src="images/white.jpg" alt="clean-usnob" width="1" height="1">
            </td>
            <td width="75%" valign="middle">
              <a href="https://arxiv.org/pdf/2105.09279.pdf">
                <papertitle>Unsupervised Discriminative Learning of Sounds for Audio Event Classification</papertitle>
              </a>
              <br>
              Sascha Hornauer, <strong>Ke Li</strong>, Stella X. Yu, Shabnam Ghaffarzadegan, Liu Ren
              <br>
              <em>ICASSP</em>, 2021
              <br>
              <a href="https://arxiv.org/abs/2105.09279">Arxiv</a> | <a href="https://www1.icsi.berkeley.edu/~stellayu/publication/doc/2021audioICASSPslides.pdf">Slides</a>
              <br>A self-supervised learning model that can transfer knowledge across audio datasets and deliver on-par performance with ImageNet pre-training.
              <p></p>
          </td> -->

          <tr>
            <td style="padding:8px;width:1%;vertical-align:middle">
              <img src="images/white.jpg" alt="clean-usnob" width="1" height="1">
            </td>
            <td width="75%" valign="middle">
              <a href="https://arxiv.org/pdf/2003.13962.pdf">
                <papertitle>Multi-Modal Graph Neural Network for Joint Reasoning on Vision and Scene Text</papertitle>
              </a>
              <br>
              Difei Gao*, <strong>Ke Li</strong>*, Ruiping Wang, Shiguang Shan, Xilin Chen
              <br>
              <em>CVPR</em>, 2020
              <br>
              <a href="https://arxiv.org/abs/2003.13962">Arxiv</a> | <a href="https://github.com/likenneth/mmgnn_textvqa">Code</a> | <a href="https://openaccess.thecvf.com/content_CVPR_2020/supplemental/Gao_Multi-Modal_Graph_Neural_CVPR_2020_supplemental.pdf">Supp</a> | <a href="https://www.youtube.com/watch?v=Sw1s8LWg1ss">Video</a>
              <br>Texts spotted in daily images could be rare, polysemous, and ambiguous, but we can pin down their semantics by across-modality message passing.
              <p></p>
            </td>
          </tr>

        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:center;font-size:small;">
                Template from <a href="https://https://jonbarron.info/">Jon Barron's website</a>
                <br>
                Last update: 01/2023
              </p>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>
</body>

</html>
